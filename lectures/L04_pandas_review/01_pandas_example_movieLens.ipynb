{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Pandas Example: MovieLens Data\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Learn how to download file from internet using the [requests](https://requests.readthedocs.io/en/master/) library\n",
    "- Know how to operate on a `.zip` file in memory, without writing to hard drive\n",
    "- Practice merging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note: requires internet access to run.**  \n",
    "\n",
    "This Jupyter notebook was originally created in 2016 by Dave Backus, Chase Coleman, Brian LeBlanc, and Spencer Lyon for the NYU Stern course [Data Bootcamp](http://databootcamp.nyuecon.com/).\n",
    "\n",
    "The notebook has been modified for this course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import pandas as pd             # data package\n",
    "import matplotlib.pyplot as plt # graphics \n",
    "import datetime as dt           # date tools, used to note current date  \n",
    "\n",
    "# these are new \n",
    "import os                       # operating system tools (check files)\n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import shutil                   # file management tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MovieLens data \n",
    "\n",
    "The [GroupLens](https://grouplens.org/) team at the University of Minnesota has prepared many datasets\n",
    "\n",
    "One is called [MovieLens](https://grouplens.org/datasets/movielens/), and contains millions of movie ratings by viewers and users of the MovieLens website\n",
    "\n",
    "We will use a small subset of the data with 100,000 ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This data comes in a `.zip` file that contains a handful of csv's and a readme\n",
    "\n",
    "Here are some details about the zipped files:\n",
    "\n",
    "* `ratings.csv`:  each line is an individual film rating with the rater and movie id's and the rating.  Order:  `userId, movieId, rating, timestamp`. \n",
    "* `tags.csv`:  each line is a tag on a specific film.  Order:  `userId, movieId, tag, timestamp`. \n",
    "* `movies.csv`:  each line is a movie name, its id, and its genre.  Order:  `movieId, title, genres`.  Multiple genres are separated by \"pipes\" `|`.   \n",
    "* `links.csv`:  each line contains the movie id and corresponding id's at [IMBd](http://www.imdb.com/) and [TMDb](https://www.themoviedb.org/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are interested in the `ratings.csv` and `movies.csv` files as pandas DataFrames\n",
    "\n",
    "There are at least two approaches to doing this:\n",
    "\n",
    "1. Download the file to the hard drive, unzip manually, then come back and use `pd.read_csv`\n",
    "2. Have Python download the file, learn to use Python to handle zip files, then use `pd.read_csv`\n",
    "\n",
    "The first option is likely easier, but the second is more powerful\n",
    "\n",
    "We will choose option 2 here as it gives us a chance to learn more \"real-world\" data+Python skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Why do it the hard way?**\n",
    "\n",
    "- It builds character\n",
    "- Entire analysis can be self-contained in our notebook, no external *by hand* steps  needed\n",
    "- Can be applied to other datasets, as we'll surely see a zip file again in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automated file download \n",
    "\n",
    "**WANT:** create pandas DataFrames from the `ratings.csv` and `movies.csv` files in the zipfile on the GroupLens website\n",
    "\n",
    "Let's unpack what steps need to happen:\n",
    "\n",
    "1. Download the file: we'll use the [requests](http://docs.python-requests.org/) package\n",
    "2. Unpack raw downloaded content as file: using built-in [io](https://docs.python.org/3.5/library/io.html) module's `io.BytesIO`\n",
    "3. Access csv files inside the zip file: using built-in [zipfile](https://docs.python.org/3.5/library/zipfile.html) module to read csv's from zip\n",
    "4. Read in csvs: easy part -- using `pd.read_csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Digression 1\n",
    "\n",
    "The `requests` documentation states\n",
    "\n",
    ">Recreational use of other HTTP libraries may result in dangerous side-effects, including: security vulnerabilities, verbose code, reinventing the wheel, constantly reading documentation, depression, headaches, or even death.\n",
    "\n",
    "We whole-heartedly agree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Digression 2\n",
    "\n",
    "We found this [Stack Overflow exchange](http://stackoverflow.com/questions/23419322/download-a-zip-file-and-extract-it-in-memory-using-python3) helpful when creating this solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 1: Download the file\n",
    "\n",
    "Let's get to it!\n",
    "\n",
    "Here we download the file and print out some information about the response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#  Step 1 -- download the file \n",
    "url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "res = requests.get(url) \n",
    "\n",
    "# (sub-step, see what the response looks like)\n",
    "print('Response status code:', res.status_code)\n",
    "print('Response type:', type(res))\n",
    "print('Response .content:', type(res.content)) \n",
    "print('Response headers:\\n', res.headers, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 2: read file as bytes\n",
    "\n",
    "The ZipFile is a binary file format (not plain text)\n",
    "\n",
    "For this reason we need to treat the contents of the file as bytes\n",
    "\n",
    "We'll load in `res.content` into an instance of `io.BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2 -- read bytes of response contentonvert bytes to zip file  \n",
    "bytes = io.BytesIO(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 3: Interpret bytes as ZipFile\n",
    "\n",
    "Now we have downloaded file, and interpreted as a binary source (`BytesIO`)\n",
    "\n",
    "This is not just any binary file, but rather a zip compressed file\n",
    "\n",
    "Python knows how to handle these using the built-in `zipfile` module\n",
    "\n",
    "Below we tell Python to interpret the `BytesIO` as a ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3 -- Interpret bytes as zipfile\n",
    "zip = zf.ZipFile(bytes)\n",
    "print('Type of zipfile object:', type(zip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now that we have a ZipFile, we need to explore what is inside\n",
    "\n",
    "The `ZipFile` class has a handy method named `namelist` \n",
    "\n",
    "This method lists all folders and files in the zip archive\n",
    "\n",
    "Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# (sub-step, inspect the file)\n",
    "names = zip.namelist()\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our target `ratings.csv` and `movies.csv` files are there\n",
    "\n",
    "However, they are in a folder named `ml-latest-small`\n",
    "\n",
    "We could write out the \"path\" to those files by hand, but instead we'll let Python find them for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_fn = [n for n in names if \"movies\" in n][0]\n",
    "ratings_fn = [n for n in names if \"ratings\" in n][0]\n",
    "\n",
    "print(\"The path to movies.csv is:\", movie_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 4: `pd.read_csv` the Files\n",
    "\n",
    "Now that we have the ZipFile **and** the path to our csvs, let's read them in as DataFrames\n",
    "\n",
    "For this we'll use our friend `pd.read_csv`\n",
    "\n",
    "We need to call the `.open` method on our zipfile\n",
    "\n",
    "This method expects the path to the file we need to open, these are saved in `movie_fn` and `ratings_fn` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and read csv's\n",
    "movies  = pd.read_csv(zip.open(movie_fn))\n",
    "ratings = pd.read_csv(zip.open(ratings_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "movies.info()\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.info()\n",
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Organization\n",
    "\n",
    "The movie ratings in the dataframe `ratings` give us individual opinions about movies, but they don't include the name of the movie.  \n",
    "\n",
    "**Why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Normalization\n",
    "\n",
    "Storing movie names in rating DataFrame would cause movie name to be repeated many times\n",
    "\n",
    "The string \"Grumpier Old Men (1995)\" takes up more space in a file than the integer `3`\n",
    "\n",
    "So, the GroupLens team decided to store the movie name in `movies.csv`, and a `movidId` column that is an integer\n",
    "\n",
    "In other files, they can use just the `movieId` column\n",
    "\n",
    "This is an eample of a relational database (think SQL) technique known as [normalization](https://en.wikipedia.org/wiki/Database_normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Why normalize?**\n",
    "\n",
    "There are many benefits to normalization, but two that immediately come to mind are:\n",
    "\n",
    "1. Save storage space: movie title (and genres in this example) are not repeated for each rating\n",
    "2. Easier to maintain/update\n",
    "\n",
    "For the second point, suppose the GroupLens team wanted to include the movie's director\n",
    "\n",
    "In the current, normalized format they would add a `director` column to `movies.csv` and have one row to update per movie\n",
    "\n",
    "If they instead chose to put the movie title inside the `ratings.csv` they would have to find all occurances of each movie and add the director"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining ratings and movies\n",
    "\n",
    "We **want** to be able to analyze the ratings for movies, and associate those ratings with a movie name\n",
    "\n",
    "We need a way to bring in the movie title information into the `ratings` DataFrame\n",
    "\n",
    "This is a perfect use case for `merge`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's start with a small example, just the first three rows of ratings:\n",
    "\n",
    "Here's what this looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's see what happens when we `merge` this with the `movies` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head(3).merge(movies, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a breakdown of what happened:\n",
    "\n",
    "- For each row in `ratings.head(3)` pandas found the `movieId`\n",
    "- It then looked for row(s) in `movies` that had a matching `movieId`\n",
    "- It then added columns `title` and `genres` alongside existing columns from `ratings` (`userId`, `rating`, `timestamp`) to form combined DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's now apply this `merge` to the whole `ratings` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "combo = pd.merge(ratings, movies,   # left and right df's\n",
    "                 how='left',        # add to left \n",
    "                 on='movieId'       # link with this variable/column \n",
    "                ) \n",
    "\n",
    "print('Dimensions of ratings:', ratings.shape)\n",
    "print('Dimensions of movies:', movies.shape)\n",
    "print('Dimensions of new df:', combo.shape)\n",
    "\n",
    "combo.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise.** Some of these we know how to do, the others we don't.  For the ones we know, what is the answer?  For the others, what (in loose terms) do we need to be able to do to come up with an answer?  \n",
    "\n",
    "* What is the overall average rating?  \n",
    "* What is the overall distribution of ratings?  \n",
    "* What is the average rating of each movie?  \n",
    "* How many ratings does each movie get?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Your code/idea here -- average rating\n",
    "combo['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Your code/idea here -- distribution of ratings\n",
    "fig, ax = plt.subplots()\n",
    "bins = [bin/100 for bin in list(range(25, 550, 50))]\n",
    "print(bins)\n",
    "combo['rating'].plot(kind='hist', ax=ax, bins=bins, color='blue', alpha=0.5)\n",
    "ax.set_xlim(0,5.5)\n",
    "ax.set_ylabel('Number')\n",
    "ax.set_xlabel('Rating')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go \n",
    "\n",
    "trace = go.Histogram(\n",
    "    x=combo['rating'],\n",
    "    name='control',\n",
    "    autobinx=False,\n",
    "    xbins=dict(\n",
    "        start=.5,\n",
    "        end=5.0,\n",
    "        size=0.5\n",
    "    ),\n",
    "    marker_color='Blue',\n",
    "    opacity=0.75\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Distribution of ratings',\n",
    "    xaxis_title='Rating value',\n",
    "    yaxis_title='Count',\n",
    "    bargap=0.01,\n",
    "    bargroupgap=0.1,\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Your code/idea here -- average rating of each movie\n",
    "\n",
    "# average for a specific movie \n",
    "combo[combo['movieId']==31]['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# average for all movies (spoiler we will learn this next time!!)\n",
    "ave_mov = combo['rating'].groupby(combo['movieId']).mean()\n",
    "ave_mov.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Your code/idea here -- number of ratings for each movie\n",
    "\n",
    "# number of ratings for a single movie\n",
    "combo[combo['movieId']==31]['rating'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# number of ratings for all movies (another spoiler!)\n",
    "combo['rating'].groupby(combo['movieId']).count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources \n",
    "\n",
    "The [Pandas docs](http://pandas.pydata.org/pandas-docs/stable/merging.html) are ok, but we prefer the Data Carpentry [guide](http://www.datacarpentry.org/python-ecology-lesson/04-merging-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "css",
   "language": "python",
   "name": "css"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
