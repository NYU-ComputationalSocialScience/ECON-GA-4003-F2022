{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SQL Introduction\n",
    "\n",
    "We will learn how to use SQL today (mostly by example)\n",
    "\n",
    "Our example data comes from the [Instacart dataset](./01_data_description.ipynb) we discussed previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from sqlalchemy.ext.declarative import declarative_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SQL (structured query language)\n",
    "\n",
    "SQL is a \"query language\" that can be used to communicate with (relational) databases.\n",
    "\n",
    "SQL itself is more of a standard for a language to communicate with databases rather than an implemented programming language which means that each database creates their own implementation of how SQL commands get translated into queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**What problem does SQL solve?**\n",
    "\n",
    "1. Straightforward way to ingest data from a database\n",
    "2. Industry standard to make database code/requirements (nearly) compatible\n",
    "3. The implementations often provide great ways to provide multiple levels of \"access\" to a dataset\n",
    "  - Some users will be \"data users\" and will use the data in their projects -- These users can get away with \"read only access\" to the database\n",
    "  - Other users will be \"data creators\" and will maintain and update the data stored in the database -- These users will need to be able to either add data or participate through other administration roles\n",
    "4. Allows administrators to impose strict requirements across the data -- For example, could impose a uniqueness constraint if we did not want an email to correspond to more than one user etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Our focus today**\n",
    "\n",
    "Our main focus for this class will be on introducing how to be \"database users\" rather than \"database administrators\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SQL and SQLAlchemy\n",
    "\n",
    "We'll now discuss a few details of SQL and SQLAlchemy:\n",
    "\n",
    "`sqlalchemy` is a Python package that allows one to generically interface with many different \"flavors\" of SQL (PostgreSQL, MySQL, SQLite, etc...) using Python code.\n",
    "\n",
    "We will only discuss it briefly today because it isn't the focus of this lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SQL Tables and Types\n",
    "\n",
    "As we mentioned, one of the benefits of SQL is that it allows those who are creating the databases to impose tight requirements on what is contained in the data:\n",
    "\n",
    "* **Tables**: SQL allows one to specify a table with pre-defined columns, cross-table restrictions, and more\n",
    "* **Types**: Each column in a SQL table must have a specified type. These types are mostly the \"usual suspects\"\n",
    "  - Boolean\n",
    "  - Date\n",
    "  - Numeric (Float, Integer, ...)\n",
    "  - String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Declaring table structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class Aisles(Base):\n",
    "    __tablename__ = \"aisles\"\n",
    "    aisle_id = sa.Column(sa.Integer, primary_key=True)\n",
    "    aisle = sa.Column(sa.String)\n",
    "\n",
    "\n",
    "class Departments(Base):\n",
    "    __tablename__ = \"departments\"\n",
    "    department_id = sa.Column(sa.Integer, primary_key=True)\n",
    "    department = sa.Column(sa.String)\n",
    "\n",
    "\n",
    "class Products(Base):\n",
    "    __tablename__ = \"products\"\n",
    "    product_id = sa.Column(sa.Integer, primary_key=True)\n",
    "    product_name = sa.Column(sa.String)\n",
    "    aisle_id = sa.Column(sa.Integer)  # One can set these to reference the aisles/departments tables\n",
    "    department_id = sa.Column(sa.Integer)\n",
    "\n",
    "\n",
    "class Orders(Base):\n",
    "    __tablename__ = \"orders\"\n",
    "    order_id = sa.Column(sa.Integer, primary_key=True)\n",
    "    user_id = sa.Column(sa.Integer)\n",
    "    eval_set = sa.Column(sa.String)\n",
    "    order_number = sa.Column(sa.Integer)\n",
    "    order_dow = sa.Column(sa.Integer)\n",
    "    order_hour_of_day = sa.Column(sa.Integer)\n",
    "    days_since_prior_order = sa.Column(sa.Integer)\n",
    "\n",
    "\n",
    "class ProductsOrdered(Base):\n",
    "    __tablename__ = \"products_ordered\"\n",
    "    order_id = sa.Column(sa.Integer, primary_key=True)\n",
    "    product_id = sa.Column(sa.Integer, primary_key=True)\n",
    "    add_to_cart_order = sa.Column(sa.Integer)\n",
    "    reordered = sa.Column(sa.Boolean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Dump data into database\n",
    "\n",
    "We're going to postpone a detailed discussion on what happens next for now...\n",
    "\n",
    "The tl;dr is that the code cell below is completely commented out. That cell takes the csv files that we previously saw and loads them in to a SQLite database\n",
    "\n",
    "It isn't a very effiicent operation, so we've done it for you and uploaded the results.\n",
    "\n",
    "The code cell two beneath this one will check the database already exists, if not it will download it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Uncomment if the data needs to be fixed or updated\n",
    "# # Create a SQL alchemy engine and add table information to the engine\n",
    "# os.remove(\"~/Data/instacart/instacart.db\")\n",
    "# eng = sa.create_engine(\"sqlite:///instacart.db\")\n",
    "# Base.metadata.create_all(eng)\n",
    "\n",
    "# Session = sa.orm.sessionmaker(bind=eng)\n",
    "\n",
    "# # Create table -> filename pairs\n",
    "# table_to_file = [\n",
    "#     (Aisles, \"~/Data/instacart/aisles.parquet\"),\n",
    "#     (Departments, \"~/Data/instacart/departments.parquet\"),\n",
    "#     (Products, \"~/Data/instacart/products.parquet\"),\n",
    "#     (Orders, \"~/Data/instacart/orders.parquet\"),\n",
    "#     (ProductsOrdered,  \"~/Data/instacart/order_products_all.parquet\"),\n",
    "# ]\n",
    "\n",
    "# session = Session()\n",
    "# # Delete any data from previous inserts\n",
    "# for (_t, _csv) in table_to_file:\n",
    "#     session.execute(_t.__table__.delete())\n",
    "#     session.commit()\n",
    "\n",
    "# # Insert data\n",
    "# for (_t, _f) in table_to_file:\n",
    "#     # Read parquet file and put into the list of dictionaries\n",
    "#     _rows = pd.read_parquet(_f).to_sql(\n",
    "#         _t.__tablename__, eng, if_exists=\"append\", index=False\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_db():\n",
    "    if os.path.exists(\"instacart.db\"):\n",
    "        print(\"Already have file\")\n",
    "        return\n",
    "    url = \"https://compsosci-resources.s3.amazonaws.com/instacart/instacart.db.zip\"\n",
    "    res = requests.get(url)\n",
    "    if not res.ok:\n",
    "        raise Exception(\"Could not download database\")\n",
    "    \n",
    "    with zipfile.ZipFile(BytesIO(res.content)) as z:\n",
    "        z.extract(\"instacart.db\")\n",
    "    \n",
    "download_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A SQLAlchemy Engine\n",
    "\n",
    "In order to access the data in the database, we need a sqlalchemy engine\n",
    "\n",
    "This is a type provided by sqlalchemy that (1) knows how to interact with a database and (2) abstracts over the type of database so we can use the same Python code to interact with multiple database types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create a SQL alchemy engine and add table information to the engine\n",
    "eng = sa.create_engine(\"sqlite:///instacart.db\")\n",
    "\n",
    "Session = sa.orm.sessionmaker(bind=eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading data from a SQL database\n",
    "\n",
    "Unless you end up becoming a data engineer, you will spend most of your time interacting with an already created database that others manage...\n",
    "\n",
    "Because of this, we will spend most of our time focused on reading data from a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### SQL Read Commands\n",
    "\n",
    "We will run the raw SQL commands into the SQLAlchemy engine, but you could interact with the engine using SQLAlchemy\n",
    "\n",
    "**Note**: It is good practice to capitalize the SQL keywords -- For example, rather than write `select` or `from`, you should write `SELECT` and `FROM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def run_query(eng, query, str_length=30):\n",
    "    with eng.connect() as conn:\n",
    "        result = conn.execute(query)\n",
    "        cols = result.keys()\n",
    "        vals = result.fetchmany(5)\n",
    "\n",
    "        fmter = (\"{\" + f\":<{str_length}\" + \"}\") * len(cols)\n",
    "        print(fmter.format(*cols))\n",
    "        for _vals in vals:\n",
    "            _pvals = map(lambda x: str(x)[:str_length], _vals)\n",
    "            print(fmter.format(*_pvals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### SELECT/FROM\n",
    "\n",
    "The most fundamental read command in SQL combines the `SELECT` statement with the `FROM` statement.\n",
    "\n",
    "* `SELECT` specifies what data to read (and what to call it)\n",
    "* `FROM` specifies where that data can be read from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Select all columns from a single table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM products\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Select certain columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT product_id, aisle_id, department_id\n",
    "        FROM products\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Select and rename certain columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT product_id AS pid, aisle_id AS aid, department_id AS did\n",
    "        FROM products\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Reference table using abbreviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT p.product_id AS pid, p.aisle_id, p.department_id\n",
    "        FROM products p\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Select functions of columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT product_id AS pid, aisle_id, department_id, aisle_id + department_id AS a_d_id\n",
    "        FROM products p\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### JOIN\n",
    "\n",
    "SQL is a relational database which means that\n",
    "\n",
    "1. We will typically store data in multiple tables\n",
    "2. We'd like to be able to combine and manipulate data from multiple tables\n",
    "\n",
    "`JOIN` allows us bring together two (or more) datasets into a single query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Select all columns from two tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM products p\n",
    "        JOIN aisles a ON (p.aisle_id=a.aisle_id)\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Select subset of columns from each table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT p.product_name, p.aisle_id, p.department_id, a.aisle\n",
    "        FROM products p\n",
    "        JOIN aisles a ON (p.aisle_id=a.aisle_id)\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Select data with different joins**\n",
    "\n",
    "The merges that we've done using pandas use the same notation as SQL joins:\n",
    "\n",
    "- `LEFT`: Use values from the left table to merge datasets\n",
    "- `RIGHT`: Use values from the right table to merge datasets\n",
    "- `INNER`: Only keep values contained in both the left and right datasets\n",
    "- `OUTER`: Keep all values contained in either the left or right dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT p.product_name, p.aisle_id, p.department_id, a.aisle\n",
    "        FROM products p\n",
    "        INNER JOIN aisles a ON (p.aisle_id=a.aisle_id)\n",
    "        \"\"\"\n",
    "\n",
    "# In this case they're all the same because there is no\n",
    "# missing data...\n",
    "run_query(eng, query, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Select data with multiple joins**\n",
    "\n",
    "We don't have to restrict ourselves to only combining two datasets -- We can combine as many as we'd like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT p.product_name, a.aisle, d.department\n",
    "        FROM products p\n",
    "        LEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\n",
    "        LEFT JOIN departments d ON (p.department_id=d.department_id)\n",
    "        \"\"\"\n",
    "\n",
    "# In this case they're all the same because there is no\n",
    "# missing data...\n",
    "run_query(eng, query, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### WHERE\n",
    "\n",
    "We are often interested in working with subsets of the data rather than selecting all of the rows.\n",
    "\n",
    "SQL allows us to specify certain conditions to restrict the set of observations that are returned using the `WHERE` clause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Retrieve certain groups** (compare  strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT p.product_name, a.aisle, d.department\n",
    "        FROM products p\n",
    "        LEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\n",
    "        LEFT JOIN departments d ON (p.department_id=d.department_id)\n",
    "        WHERE d.department = 'snacks'\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Retrieve certain groups** (compare numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT p.product_name, a.aisle, d.department, a.aisle_id\n",
    "        FROM products p\n",
    "        LEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\n",
    "        LEFT JOIN departments d ON (p.department_id=d.department_id)\n",
    "        WHERE a.aisle_id > 132\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Multiple conditions**\n",
    "\n",
    "We use `AND` and `OR` to specify the boolean condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT p.product_name, a.aisle, d.department, a.aisle_id, d.department_id\n",
    "        FROM products p\n",
    "        LEFT JOIN aisles a ON (p.aisle_id=a.aisle_id)\n",
    "        LEFT JOIN departments d ON (p.department_id=d.department_id)\n",
    "        WHERE a.aisle_id > 100 OR d.department_id<10\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Retrieve the most recent data** (compare datetime)\n",
    "\n",
    "Imagine we had a table that contained quarterly sales\n",
    "\n",
    "| dt | store_id | sales |\n",
    "| ---- | ---- | ---- |\n",
    "| 2020-03-31 | 1 | 100 |\n",
    "| 2020-06-30 | 1 | 200 |\n",
    "| 2020-09-30 | 1 | 300 |\n",
    "| 2020-12-31 | 1 | 400 |\n",
    "| 2020-03-31 | 2 | 1000 |\n",
    "| 2020-06-30 | 2 | 2000 |\n",
    "| 2020-09-30 | 2 | 3000 |\n",
    "| 2020-12-31 | 2 | 4000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "If we wanted to select only the observations from quarter 1, we could write\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM sales\n",
    "WHERE dt<'2020-04-01'\n",
    "```\n",
    "\n",
    "| dt | store_id | sales |\n",
    "| ---- | ---- | ---- |\n",
    "| 2020-03-31 | 1 | 100 |\n",
    "| 2020-03-31 | 2 | 1000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "If we wanted to select observations from Q3 and Q4, we could write\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM sales\n",
    "WHERE dt>'2020-06-31'\n",
    "```\n",
    "\n",
    "| dt | store_id | sales |\n",
    "| ---- | ---- | ---- |\n",
    "| 2020-09-30 | 1 | 300 |\n",
    "| 2020-12-31 | 1 | 400 |\n",
    "| 2020-09-30 | 2 | 3000 |\n",
    "| 2020-12-31 | 2 | 4000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### GROUP BY\n",
    "\n",
    "The `GROUP BY` argument allows us to aggregate certain groups of values (much like the pandas `groupby` method).\n",
    "\n",
    "When you perform a `GROUP BY`, any column that is not an element of the \"group\" must have a reduction function applied to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Group by single column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT order_dow, COUNT(user_id) AS norder\n",
    "        FROM orders o\n",
    "        GROUP BY order_dow\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Group by multiple columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT user_id, order_dow, COUNT(order_id) AS norder\n",
    "        FROM orders o\n",
    "        GROUP BY user_id, order_dow\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Aggregate multiple columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT user_id, order_dow,\n",
    "               COUNT(order_id) AS norder,\n",
    "               AVG(days_since_prior_order) AS avg_days_since_order\n",
    "        FROM orders o\n",
    "        GROUP BY user_id, order_dow\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### ORDER BY\n",
    "\n",
    "`ORDER BY` allows us to sort the output of a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Order by single column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT order_id, user_id, order_number, days_since_prior_order\n",
    "        FROM orders o\n",
    "        ORDER BY user_id\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Order by multiple columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT order_id, user_id, order_number, days_since_prior_order\n",
    "        FROM orders o\n",
    "        ORDER BY user_id, order_number\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Order by ascending/descending**\n",
    "\n",
    "The keywords for specifying the order of ordering are `ASC` (for ascending) and `DESC` (for descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT order_id, user_id, order_number, days_since_prior_order\n",
    "        FROM orders o\n",
    "        WHERE days_since_prior_order < 30\n",
    "        ORDER BY days_since_prior_order DESC, user_id ASC\n",
    "        \"\"\"\n",
    "\n",
    "run_query(eng, query, 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### LIMIT\n",
    "\n",
    "`LIMIT` is a SQL clause that specifies the (maximum) number of rows that should be returned.\n",
    "\n",
    "It performs the same role as the pandas dataframe `head` method -- It allows you to select the $n$ largest/smallest values or simply get a preview of your data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Retrieve first n rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "query_l10 = \"\"\"\n",
    "        SELECT *\n",
    "        FROM orders o\n",
    "        LIMIT 10\n",
    "        \"\"\"\n",
    "\n",
    "_ = eng.execute(query_l10).fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "query_all = \"\"\"\n",
    "        SELECT *\n",
    "        FROM orders o\n",
    "        \"\"\"\n",
    "\n",
    "_ = eng.execute(query_all).fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reading with pandas\n",
    "\n",
    "We have directly used SQLAlchemy's engine to read in data up until this point, but we can also read from the engine using pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT order_id, user_id, order_number, days_since_prior_order\n",
    "        FROM orders o\n",
    "        ORDER BY days_since_prior_order DESC, user_id ASC\n",
    "        \"\"\"\n",
    "\n",
    "pd.read_sql(query, eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redoing our reorder example in SQL using a `WITH` clause\n",
    "\n",
    "`WITH` clauses allow us to define a \"temporary table\" that can be used in a subsequent query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    WITH agg_po AS (\n",
    "        SELECT po.product_id,\n",
    "               COUNT(po.add_to_cart_order) AS norder,\n",
    "               SUM(po.reordered) AS nreorder\n",
    "        FROM products_ordered po\n",
    "        LEFT JOIN orders o ON po.order_id=o.order_id\n",
    "        WHERE o.days_since_prior_order IS NOT NULL\n",
    "        GROUP BY po.product_id\n",
    "    )\n",
    "    SELECT apo.product_id, apo.norder, apo.nreorder,\n",
    "           (apo.nreorder*1.0 / apo.norder) AS frac_reorder,\n",
    "           p.product_name, p.aisle_id, p.department_id\n",
    "    FROM agg_po as apo\n",
    "    LEFT JOIN products p ON apo.product_id=p.product_id\n",
    "    WHERE apo.nreorder > 10\n",
    "    ORDER BY frac_reorder DESC\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, eng)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "06e05088bf2d2704501f452c5673235c92421ea24b381cad1d147a1ece3057ad"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
